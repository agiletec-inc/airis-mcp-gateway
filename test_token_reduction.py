#!/usr/bin/env python3
"""
OpenMCP Lazy Loading Pattern„ÅÆ„Éà„Éº„ÇØ„É≥ÂâäÊ∏õÂäπÊûú„ÇíÊ∏¨ÂÆö

ÊØîËºÉ:
1. Docker MCP Gateway (http://localhost:9090/sse) - „Ç™„É™„Ç∏„Éä„É´
2. FastAPI Proxy (http://localhost:8001/api/v1/mcp/sse) - Schema Partitioned
"""

import asyncio
import httpx
import json
from typing import Dict, Any, Optional


async def fetch_tools_via_gateway(url: str) -> Optional[Dict[str, Any]]:
    """
    MCP Gateway„Åã„ÇâSSEÁµåÁî±„Åßtools/list„ÇíÂèñÂæó

    Args:
        url: SSE endpoint URL

    Returns:
        tools/list „É¨„Çπ„Éù„É≥„Çπ
    """
    print(f"\nüîå Connecting to: {url}")

    async with httpx.AsyncClient(timeout=30.0) as client:
        async with client.stream("GET", url) as response:
            print(f"   Status: {response.status_code}")

            # SSE„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË™≠„ÅøÂèñ„Çã
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data_str = line[6:]

                    try:
                        data = json.loads(data_str)

                        # tools/list „É¨„Çπ„Éù„É≥„Çπ„ÇíÊé¢„Åô
                        if isinstance(data, dict):
                            method = data.get("method")

                            if method == "tools/list":
                                print(f"   ‚úÖ Received tools/list response")
                                return data

                            # „Ç®„É≥„Éâ„Éù„Ç§„É≥„ÉàÈÄöÁü•„ÅØÁÑ°Ë¶ñ
                            if "event" in line and "endpoint" in line:
                                continue

                    except json.JSONDecodeError:
                        pass

    return None


def calculate_token_estimate(data: Dict[str, Any]) -> int:
    """
    JSON„Éá„Éº„Çø„ÅÆ„Éà„Éº„ÇØ„É≥Êï∞„ÇíÊé®ÂÆö

    Ëøë‰ºº: 1„Éà„Éº„ÇØ„É≥ ‚âà 4ÊñáÂ≠ó
    """
    json_str = json.dumps(data)
    return len(json_str) // 4


def analyze_tools(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    tools/list„É¨„Çπ„Éù„É≥„Çπ„ÇíÂàÜÊûê

    Returns:
        {
            "tool_count": int,
            "total_tokens": int,
            "tools": [{"name": str, "tokens": int}]
        }
    """
    if "result" not in data or "tools" not in data["result"]:
        return {
            "tool_count": 0,
            "total_tokens": 0,
            "tools": []
        }

    tools = data["result"]["tools"]
    tool_count = len(tools)
    total_tokens = calculate_token_estimate(data)

    tool_details = []
    for tool in tools:
        tool_name = tool.get("name", "unknown")
        tool_tokens = calculate_token_estimate(tool)
        tool_details.append({
            "name": tool_name,
            "tokens": tool_tokens
        })

    # „Éà„Éº„ÇØ„É≥Êï∞„Åß„ÇΩ„Éº„Éà
    tool_details.sort(key=lambda x: x["tokens"], reverse=True)

    return {
        "tool_count": tool_count,
        "total_tokens": total_tokens,
        "tools": tool_details
    }


async def main():
    """„É°„Ç§„É≥Âá¶ÁêÜ"""

    print("=" * 80)
    print("üß™ OpenMCP Lazy Loading Pattern - Token Reduction Test")
    print("=" * 80)

    # 1. Docker MCP GatewayÔºà„Ç™„É™„Ç∏„Éä„É´Ôºâ
    print("\nüìä Step 1: Fetch from Docker MCP Gateway (Original)")
    gateway_data = await fetch_tools_via_gateway("http://mcp-gateway:9090/sse")

    if not gateway_data:
        print("‚ùå Failed to fetch from Gateway")
        return

    gateway_analysis = analyze_tools(gateway_data)

    print(f"\n   Tool Count: {gateway_analysis['tool_count']}")
    print(f"   Total Tokens: {gateway_analysis['total_tokens']:,}")
    print(f"\n   Top 10 Tools by Token Size:")
    for i, tool in enumerate(gateway_analysis['tools'][:10], 1):
        print(f"      {i:2}. {tool['name']:30} {tool['tokens']:5,} tokens")

    # 2. FastAPI ProxyÔºàSchema PartitionedÔºâ
    print("\nüìä Step 2: Fetch from FastAPI Proxy (Schema Partitioned)")
    proxy_data = await fetch_tools_via_gateway("http://localhost:8000/api/v1/mcp/sse")

    if not proxy_data:
        print("‚ùå Failed to fetch from Proxy")
        return

    proxy_analysis = analyze_tools(proxy_data)

    print(f"\n   Tool Count: {proxy_analysis['tool_count']}")
    print(f"   Total Tokens: {proxy_analysis['total_tokens']:,}")
    print(f"\n   Top 10 Tools by Token Size:")
    for i, tool in enumerate(proxy_analysis['tools'][:10], 1):
        print(f"      {i:2}. {tool['name']:30} {tool['tokens']:5,} tokens")

    # 3. ÊØîËºÉ
    print("\n" + "=" * 80)
    print("üìä Comparison Results")
    print("=" * 80)

    token_reduction = gateway_analysis['total_tokens'] - proxy_analysis['total_tokens']
    reduction_percent = (token_reduction / gateway_analysis['total_tokens'] * 100) if gateway_analysis['total_tokens'] > 0 else 0

    print(f"\n   Original (Gateway):     {gateway_analysis['total_tokens']:6,} tokens")
    print(f"   Partitioned (Proxy):    {proxy_analysis['total_tokens']:6,} tokens")
    print(f"   Reduction:              {token_reduction:6,} tokens ({reduction_percent:.1f}%)")

    # expandSchema „ÉÑ„Éº„É´„ÅåËøΩÂä†„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
    proxy_tools = {tool['name'] for tool in proxy_analysis['tools']}
    has_expand_schema = "expandSchema" in proxy_tools

    print(f"\n   expandSchema tool added: {'‚úÖ Yes' if has_expand_schema else '‚ùå No'}")

    # ÁõÆÊ®ôÈÅîÊàêÁ¢∫Ë™ç
    print("\n" + "=" * 80)
    print("üéØ Goal Achievement")
    print("=" * 80)

    if reduction_percent >= 75:
        print(f"   ‚úÖ SUCCESS: {reduction_percent:.1f}% reduction (target: 75-90%)")
    elif reduction_percent >= 50:
        print(f"   ‚ö†Ô∏è  PARTIAL: {reduction_percent:.1f}% reduction (target: 75-90%)")
    else:
        print(f"   ‚ùå INSUFFICIENT: {reduction_percent:.1f}% reduction (target: 75-90%)")

    if has_expand_schema:
        print(f"   ‚úÖ expandSchema tool is available for on-demand schema expansion")
    else:
        print(f"   ‚ùå expandSchema tool is missing")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
